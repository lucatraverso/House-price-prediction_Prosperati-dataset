{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "prosperati.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOQppwL5UXzXRrtD52OGGxC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lucatraverso/House-price-prediction_Prosperati-dataset./blob/main/prosperati.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FNYDUqlm1OAm"
      },
      "source": [
        "#Predicción de precios de alquileres en CABA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qhhpEfURnPC7"
      },
      "source": [
        "En este colab vamos a armar un modelo para predecir precios de casas usando un dataset de Prosperati y varios algoritmos diferentes. Primero importamos las librerias y módulos necesarios."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WtTGVUsaf0tv"
      },
      "source": [
        "import pandas as pd\n",
        "import gzip\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.metrics import mean_squared_error"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IAIJDF6u13Em"
      },
      "source": [
        "##Obtencion del dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ejjLDwWBpJZ5"
      },
      "source": [
        "Ahora descargamos e importamos el dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wUJSrXXjpOxl",
        "outputId": "88760973-167c-4533-e65e-24f69bf8ed54"
      },
      "source": [
        "!wget https://storage.googleapis.com/properati-data-public/ar_properties.csv.gz"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-07-08 00:21:30--  https://storage.googleapis.com/properati-data-public/ar_properties.csv.gz\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.204.128, 64.233.187.128, 64.233.189.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.204.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 292380968 (279M) [application/octet-stream]\n",
            "Saving to: ‘ar_properties.csv.gz’\n",
            "\n",
            "ar_properties.csv.g 100%[===================>] 278.84M   108MB/s    in 2.6s    \n",
            "\n",
            "2021-07-08 00:21:32 (108 MB/s) - ‘ar_properties.csv.gz’ saved [292380968/292380968]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5XiyS3gq91c"
      },
      "source": [
        "with gzip.open('ar_properties.csv.gz') as f:\n",
        "    dataset = pd.read_csv(f)"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IlRC45yzrGnk"
      },
      "source": [
        "##Limpieza y filtrado de datos\n",
        "\n",
        "Filtramos el dataset para ver solamente alquileres en capital federal, en pesos que correspondan a casas, departamentos o ph. Tambien eliminamos columnas innecesarias.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-LOCvOesW6L"
      },
      "source": [
        "dataset = dataset[(dataset.l2 == 'Capital Federal') & \n",
        "                  (dataset.operation_type == 'Alquiler') &\n",
        "                  (dataset.price > 0) &\n",
        "                  (dataset.currency == 'ARS')]\n",
        "\n",
        "dataset = dataset[dataset.property_type == ('Departamento' or 'PH' or 'Casa')]\n",
        "\n",
        "ubicacion = dataset[['lat', 'lon']]\n",
        "\n",
        "drop = ['id', \n",
        "        'ad_type', \n",
        "        'start_date', \n",
        "        'end_date', \n",
        "        'created_on', \n",
        "        'title', \n",
        "        'description', \n",
        "        'l1', 'l2', 'l4',  \n",
        "        'l5', 'l6', \n",
        "        'lat', 'lon', \n",
        "        'price_period', \n",
        "        'operation_type', \n",
        "        'currency']\n",
        "\n",
        "dataset = dataset.drop(drop, axis=1)"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCJDV1bI2sYf"
      },
      "source": [
        "##Feature engineering\n",
        "\n",
        "Como las columnas de barrio y tipo de propiedad son de tipo categoricas, vamosa codificarlas utilizando one-hot encoding. Tambien se rellenan los valores ausentes.\n",
        "Los correspondientes a cuartos, habitaciones y baños con 0 y las superficies con el valor medio. Tambien se normalizan las superficies total y cubierta utilizando la media y desviacion del training set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJih7VaU2mYI"
      },
      "source": [
        "barrios = pd.get_dummies(dataset['l3'])\n",
        "tipos = pd.get_dummies(dataset['property_type'])\n",
        "\n",
        "dataset = dataset.drop('l3', axis=1)\n",
        "dataset = dataset.drop('property_type', axis=1)\n",
        "\n",
        "dataset = dataset.dropna()\n",
        "\n",
        "dataset = dataset.join(barrios)\n",
        "dataset = dataset.join(tipos)\n",
        "\n",
        "x_train = dataset.iloc[0:10000].drop('price', axis=1)\n",
        "y_train = dataset.iloc[0:10000:]['price']\n",
        "\n",
        "x_test = dataset.iloc[10001:].drop('price', axis=1)\n",
        "y_test = dataset.iloc[10001:]['price']\n",
        "\n",
        "def pad_and_normalize(column, media, desv):\n",
        "    '''\n",
        "    Remplaza valores vacios de una columna por la media y normaliza\n",
        "    '''\n",
        "    column = column.fillna(media)\n",
        "    column = (column - media) / desv\n",
        "    return column\n",
        "\n",
        "(sc_media, sc_desv) = (x_train['surface_covered'].mean(), x_train['surface_covered'].std())\n",
        "(st_media, st_desv) = (x_train['surface_total'].mean(), x_train['surface_total'].std())\n",
        "\n",
        "x_train['surface_covered'] = pad_and_normalize(x_train['surface_covered'], sc_media, sc_desv)\n",
        "x_train['surface_total'] = pad_and_normalize(x_train['surface_total'], st_media, st_desv)\n",
        "x_train[['rooms', 'bedrooms', 'bathrooms']] = x_train[['rooms', 'bedrooms', 'bathrooms']].fillna(0)\n",
        "\n",
        "x_test['surface_covered'] = pad_and_normalize(x_test['surface_covered'], sc_media, sc_desv)\n",
        "x_test['surface_total'] = pad_and_normalize(x_test['surface_total'], st_media, st_desv)\n",
        "x_test[['rooms', 'bedrooms', 'bathrooms']] = x_test[['rooms', 'bedrooms', 'bathrooms']].fillna(0)"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pK7ZtNHX6HW7"
      },
      "source": [
        "##Definición de modelos\n",
        "\n",
        "Vamos a usar regresión lineal y una red neuronal."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vF8p0cg27Dq7"
      },
      "source": [
        "#%% REGRESIÓN LINEAL\n",
        "\n",
        "def entrenar_rlineal(x_train, y_train, x_test, y_test):\n",
        "    modelo = LinearRegression()\n",
        "    modelo.fit(x_train, y_train)\n",
        "    y_pred = modelo.predict(x_test)\n",
        "\n",
        "    train_score = modelo.score(x_train, y_train)\n",
        "    test_score = modelo.score(x_test, y_test)\n",
        "    mserror = mean_squared_error(y_test, y_pred)\n",
        "    \n",
        "    mse = (((y_test - y_pred)**2).sum()) / len(y_test)\n",
        "\n",
        "    print('Testing linear model...')\n",
        "    print(f'Training score: {train_score:.2f}')\n",
        "    print(f'Testing score: {test_score:.2f}')\n",
        "    print(f'MSError: {mserror:.2f} | {mse:.2f}')\n",
        "    print('...')\n",
        "    return modelo\n",
        "\n",
        "\n",
        "#%% RED NEURONAL\n",
        "\n",
        "def entrenar_red(x_train, y_train, x_test, y_test, n=(100), \n",
        "                 solver='adam', lri=0.001, lr='constant'):\n",
        "    '''\n",
        "    Entrena una red \n",
        "    n: tupla con en numero de unidades por capa    \n",
        "    '''\n",
        "    nn = MLPRegressor(hidden_layer_sizes=n, \n",
        "                      activation = 'relu', \n",
        "                      solver='adam', \n",
        "                      learning_rate_init=lri,\n",
        "                      learning_rate='constant', \n",
        "                      random_state=1\n",
        "                      )\n",
        "    nn.fit(x_train, y_train)\n",
        "    y_pred = nn.predict(x_test)\n",
        "    train_score = nn.score(x_train, y_train)\n",
        "    test_score = nn.score(x_test, y_test)\n",
        "    mserror = mean_squared_error(y_test, y_pred)\n",
        "\n",
        "    print(f'Neural Net with {n} units')\n",
        "    print(f'Training score: {train_score:.2f}')\n",
        "    print(f'Testing score: {test_score:.2f}')\n",
        "    print(f'MSError: {mserror:.2f}')\n",
        "    print('...')\n",
        "    return nn"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egtxbgVi9GaY"
      },
      "source": [
        "Vamos a probar un par de configuraciones para ver que funciona mejor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p2JpCHCZ9KAO",
        "outputId": "16eb0def-93a7-4c60-d26e-ad2871ba639c"
      },
      "source": [
        "modelo_lineal = entrenar_rlineal(x_train, y_train, x_test, y_test)\n",
        "red_simple = entrenar_red(x_train, y_train, x_test, y_test, (100), 'adam', 0.1, 'adaptive')\n",
        "red_doble = entrenar_red(x_train, y_train, x_test, y_test, (100, 50), 'adam', 0.1, 'adaptive')\n",
        "red_triple = entrenar_red(x_train, y_train, x_test, y_test, (100, 50, 25), 'adam', 0.1, 'adaptive')"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing linear model...\n",
            "Training score: 0.52\n",
            "Testing score: 0.36\n",
            "MSError: 1725687145.79 | 1725687145.79\n",
            "...\n",
            "Neural Net with 100 units\n",
            "Training score: 0.57\n",
            "Testing score: 0.36\n",
            "MSError: 1716976288.12\n",
            "...\n",
            "Neural Net with (100, 50) units\n",
            "Training score: 0.70\n",
            "Testing score: 0.58\n",
            "MSError: 1116857314.68\n",
            "...\n",
            "Neural Net with (100, 50, 25) units\n",
            "Training score: 0.70\n",
            "Testing score: 0.57\n",
            "MSError: 1142053403.10\n",
            "...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u0qOLAeZT742"
      },
      "source": [
        "Ahora tomtamos la red de dos capaz ocultas para realizar mas pruebas. Vamos a convertir los precios a una escala logaritmica a ver como afecta la precision de los modelos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EXB8sSrXUxYM",
        "outputId": "22a5695f-59a4-4f58-c688-54b512e1dc33"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "y_train_log = np.log(y_train)\n",
        "y_test_log = np.log(y_test)\n",
        "\n",
        "modelo_lineal = entrenar_rlineal(x_train, y_train_log, x_test, y_test_log)\n",
        "    \n",
        "red_doble = entrenar_red(x_train, y_train_log, x_test, y_test_log, \n",
        "                         (100, 50), 'adam', 0.1, 'adaptive')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing linear model...\n",
            "Training score:  0.5774018469572362\n",
            "Testing score:  0.4560626691162659\n",
            "...\n",
            "Neural Net with (100, 50) units\n",
            "Training score:  0.5188867253553939\n",
            "Testing score:  -0.8489961152915662\n",
            "...\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}